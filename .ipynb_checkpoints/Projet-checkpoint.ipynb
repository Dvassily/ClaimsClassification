{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet méthodes pour la science des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('Dataset/claimskg_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Informations sur le dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'enregistrements : \n",
      "10000\n",
      "Nombre de colonnes : \n",
      "14\n",
      "Informations sur les colonnes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   id                      10000 non-null  object\n",
      " 1   text                    10000 non-null  object\n",
      " 2   date                    10000 non-null  object\n",
      " 3   truthRating             10000 non-null  int64 \n",
      " 4   ratingName              10000 non-null  object\n",
      " 5   author                  10000 non-null  object\n",
      " 6   headline                9882 non-null   object\n",
      " 7   named_entities_claim    9864 non-null   object\n",
      " 8   named_entities_article  6497 non-null   object\n",
      " 9   keywords                8691 non-null   object\n",
      " 10  source                  10000 non-null  object\n",
      " 11  sourceURL               10000 non-null  object\n",
      " 12  link                    10000 non-null  object\n",
      " 13  language                10000 non-null  object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "shape=df.shape\n",
    "print(\"Nombre d'enregistrements : \")\n",
    "print(shape[0])\n",
    "print(\"Nombre de colonnes : \")\n",
    "print(shape[1])\n",
    "print(\"Informations sur les colonnes\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe qu'il n'existe qu'un seul champs dont le type des valeurs est numérique : truthRating qui indique si l'affirmation est vraie, fausse ou un mélange de vraies et de fausses informations. Les autres types correspondent tous à des chaîne de caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Feature engeenering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.a. Supression des colonnes inutiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi les colonnes du Dataframe, certaines colonnes ne sont pas nécessaire pour les tâches de classification. On peut par exemple vérifier qu'il y'a une bijection entre l'ensemble des valeurs de truthRating et l'ensemble des valeurs de ratingName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truthRating  ratingName\n",
      "-1           OTHER         1761\n",
      " 1           FALSE         3665\n",
      " 2           MIXTURE       3247\n",
      " 3           TRUE          1327\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "g=df.groupby(['truthRating', 'ratingName'])\n",
    "print(g['id'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut donc supprimer au choix la colonne truthRating et ratingName car les valeurs seront de toute façon transformées lors de la création des features à l'étape suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "del df['ratingName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi supprimer la colonne language car tous les enregistrement dans le dataframe on la valeur 'English' pour cette colonne, elle n'est donc pas utile à l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "del df['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('Dataset/claimskg_columns_removed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.b. Valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous sont présentés les nombres de chaînes de caractères vides par colonnes dans le dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline : 118\n",
      "named_entities_claim : 136\n",
      "named_entities_article : 3503\n",
      "keywords : 1309\n"
     ]
    }
   ],
   "source": [
    "def count_empty_values(df):\n",
    "    columns=df.columns[df.isnull().any()].tolist()\n",
    "    for column in columns:\n",
    "        print(column + \" : \" + str(df[column].isnull().sum()))\n",
    "\n",
    "count_empty_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que toutes ces colonnes de type 'chaîne de caractère', on ne peut donc pas effectuer de calcul de moyennes pour remplir les informations manquantes. Il n'est pas non plus envisageables de supprimer les enregistrements correspondant car les autres colonnes portent des informations utiles à l'apprentissages.\n",
    "\n",
    "On s'intéresse maintenant aux enregistrements qui ne portent pas la classe cible des tâches d'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enregistrements non FALSE, TRUE ou MIXTURE : 1761\n"
     ]
    }
   ],
   "source": [
    "print(\"Enregistrements non FALSE, TRUE ou MIXTURE : \" + str(df[df['truthRating'] == -1].count()['id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme ces enregistrements ne peuvent servir pour l'apprentissage, on peut se permettre de les supprimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['truthRating'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut constater l'impact sur les valeurs manquantes des quatres colonnes contenant des valeurs nulles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "named_entities_claim : 11\n",
      "named_entities_article : 2966\n",
      "keywords : 464\n"
     ]
    }
   ],
   "source": [
    "count_empty_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On compte maintenant le nombre de date dont la valeur est unknown dans le dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3422\n"
     ]
    }
   ],
   "source": [
    "print(df[df['date'] == 'Unknown'].count()['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les date étant sous forme de chaîne de caractère, nous choisissons de les convertir en timestamp afin que les algorithmes de classification puisse trouver, s'il en existe, certaines corrélations entre l'ancienneté d'une assertion et sa veracité. Nous remplacerons les valeurs 'Unknown' par la moyenne des timestamps obtenus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.329260e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.252966e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.395176e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.395176e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.245017e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.219615e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.291072e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.472162e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.395176e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.448924e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8239 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date\n",
       "2     1.329260e+09\n",
       "3     1.252966e+09\n",
       "4     1.395176e+09\n",
       "5     1.395176e+09\n",
       "6     1.245017e+09\n",
       "...            ...\n",
       "9995  1.219615e+09\n",
       "9996  1.291072e+09\n",
       "9997  1.472162e+09\n",
       "9998  1.395176e+09\n",
       "9999  1.448924e+09\n",
       "\n",
       "[8239 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "from math import ceil\n",
    "\n",
    "def convert_to_timestamp(datestring):\n",
    "    return time.mktime(datetime.datetime.strptime(datestring, \"%Y-%m-%d\").timetuple())\n",
    "\n",
    "\n",
    "# df_feature_date = df['date'].apply(convert_to_timestamp)['date']\n",
    "\n",
    "timestamp_sum=0\n",
    "number_of_dates = 0\n",
    "for date in df['date']:\n",
    "    if date != 'Unknown':\n",
    "        timestamp_sum += convert_to_timestamp(date)\n",
    "        number_of_dates = number_of_dates + 1\n",
    "\n",
    "timestamp_mean = ceil(timestamp_sum / number_of_dates)\n",
    "\n",
    "def process_dates(date):\n",
    "    if date == 'Unknown':\n",
    "        return timestamp_mean\n",
    "    else:\n",
    "        return convert_to_timestamp(date)\n",
    "\n",
    "df_timestamp = pd.DataFrame(df['date'].apply(process_dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.c. Pré-traitement du texte d'une affirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par importer la bibliothèque NLTK (Natural Language ToolKit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on défini la fonction de pré-traitement du texte d'une affirmation.\n",
    "Celle-ci contient les étapes suivantes :\n",
    "- Suppression des formes contractées de la langue anglaise\n",
    "- Remplacement des chiffres par des mots\n",
    "- Suppression des ponctuations\n",
    "- Normalisation de la casse (tout est mis en minuscule)\n",
    "- Suppression des mots non utiles à la classification (Stop words)\n",
    "- Reduction des mots à leurs racines (Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import inflect\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "p = inflect.engine()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "def replace_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "def replace_numbers(word):\n",
    "    if (word.isdigit()):\n",
    "        return p.number_to_words(word)\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "def remove_punctuations(words):\n",
    "    return [word for word in words if word.isalpha()]\n",
    "\n",
    "def normalize_case(word):\n",
    "    return word.lower()\n",
    "\n",
    "def filter_stop_words(words):\n",
    "    return [word for word in words if not word in stop_words]\n",
    "\n",
    "def lemmatize_word(word):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(word, pos='v')\n",
    "\n",
    "def process_text(text):\n",
    "    text = replace_contractions(text)\n",
    "\n",
    "    words = tokenize(text)\n",
    "    words = map(replace_numbers, words)\n",
    "    words = remove_punctuations(words)\n",
    "    words = map(normalize_case, words)\n",
    "    words = filter_stop_words(words)\n",
    "    words = map(lemmatize_word, words)\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# df_rows_removed : DataFrame dont les enregistrements avec une valeur de truthRating égale à -1 sont supprimés\n",
    "df_rows_removed = df.copy()\n",
    "df = pd.DataFrame(df['text'].apply(process_text))\n",
    "print(df_claim_text_processed['text'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.d. Extraction des features à partir du texte de l'assertion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utilisé la classe TfidVectorizer pour produire à partir de chaque mots du texte pré-traité de chaque assertion une feature dont la valeur correspond à la fréquence d'apparition du mot dans le texte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "features_text = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "df_features_text = pd.DataFrame(\n",
    "    data=vectorizer.transform(df['text']).toarray(),\n",
    "    columns=vectorizer.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.e. Ajout de la colonne timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On définit le DataFrame 'features' comme la jointure sur l'id des features extraits du texte avec le DataFrame contenant les timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aba</th>\n",
       "      <th>abaco</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abbott</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abby</th>\n",
       "      <th>...</th>\n",
       "      <th>zip</th>\n",
       "      <th>zipper</th>\n",
       "      <th>zippo</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zombism</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>zuma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8234</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8238</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8239 rows × 10624 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaa  aaron   ab  aba  abaco  abandon  abbey  abbott  abbreviation  abby  \\\n",
       "0     0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "1     0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "2     0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "3     0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "4     0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "...   ...    ...  ...  ...    ...      ...    ...     ...           ...   ...   \n",
       "8234  0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "8235  0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "8236  0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "8237  0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "8238  0.0    0.0  0.0  0.0    0.0      0.0    0.0     0.0           0.0   0.0   \n",
       "\n",
       "      ...  zip  zipper  zippo  zombie  zombies  zombism  zone  zoo  \\\n",
       "0     ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "1     ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "2     ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "3     ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "4     ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "...   ...  ...     ...    ...     ...      ...      ...   ...  ...   \n",
       "8234  ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "8235  ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "8236  ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "8237  ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "8238  ...  0.0     0.0    0.0     0.0      0.0      0.0   0.0  0.0   \n",
       "\n",
       "      zuckerberg  zuma  \n",
       "0            0.0   0.0  \n",
       "1            0.0   0.0  \n",
       "2            0.0   0.0  \n",
       "3            0.0   0.0  \n",
       "4            0.0   0.0  \n",
       "...          ...   ...  \n",
       "8234         0.0   0.0  \n",
       "8235         0.0   0.0  \n",
       "8236         0.0   0.0  \n",
       "8237         0.0   0.0  \n",
       "8238         0.0   0.0  \n",
       "\n",
       "[8239 rows x 10624 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = df_features_text.join(df_timestamp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.e. Création des features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IV.a. Ingénierie du texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split \n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "# from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "# from time import time\n",
    "#from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "# testsize= 1-validation_size\n",
    "# seed=30\n",
    "\n",
    "\n",
    "\n",
    "# pipeline = Pipeline([('vect', TfidfVectorizer()),\n",
    "#                ('clf', SGDClassifier(loss='hinge', \n",
    "#                                      penalty='l2',\n",
    "#                                      alpha=1e-3, \n",
    "#                                      random_state=42, \n",
    "#                                      max_iter=5, tol=None)),\n",
    "#               ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# X = df_claim_text_processed['text'].values\n",
    "# y = df['truthRating']\n",
    "\n",
    "# X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "#                                               y, \n",
    "#                                               train_size=validation_size, \n",
    "#                                               random_state=seed,\n",
    "#                                               test_size=testsize)\n",
    "\n",
    "\n",
    "# t0 = time()\n",
    "# pipeline.fit(X_train, y_train)\n",
    "# print(\"Fit réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "# t0 = time()\n",
    "# result = pipeline.predict(X_test)\n",
    "# print(\"Prédiction réalisée en %0.3fs\" % (time() - t0))\n",
    "\n",
    "# print('\\n accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "# conf = confusion_matrix(y_test, result)\n",
    "# print ('\\n matrice de confusion \\n',conf)\n",
    "\n",
    "# print ('\\n',classification_report(y_test, result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
