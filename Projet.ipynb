{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet méthodes pour la science des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('Dataset/claimskg_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Informations sur le dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'enregistrements : \n",
      "10000\n",
      "Nombre de colonnes : \n",
      "14\n",
      "Informations sur les colonnes\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   id                      10000 non-null  object\n",
      " 1   text                    10000 non-null  object\n",
      " 2   date                    10000 non-null  object\n",
      " 3   truthRating             10000 non-null  int64 \n",
      " 4   ratingName              10000 non-null  object\n",
      " 5   author                  10000 non-null  object\n",
      " 6   headline                9882 non-null   object\n",
      " 7   named_entities_claim    9864 non-null   object\n",
      " 8   named_entities_article  6497 non-null   object\n",
      " 9   keywords                8691 non-null   object\n",
      " 10  source                  10000 non-null  object\n",
      " 11  sourceURL               10000 non-null  object\n",
      " 12  link                    10000 non-null  object\n",
      " 13  language                10000 non-null  object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "shape=df.shape\n",
    "print(\"Nombre d'enregistrements : \")\n",
    "print(shape[0])\n",
    "print(\"Nombre de colonnes : \")\n",
    "print(shape[1])\n",
    "print(\"Informations sur les colonnes\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On observe qu'il n'existe qu'un seul champs dont le type des valeurs est numérique : truthRating qui indique si l'affirmation est vraie, fausse ou un mélange de vraies et de fausses informations. Les autres types correspondent tous à des chaîne de caractères."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Pré-traitements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.a. Supression des colonnes inutiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parmi les colonnes du Dataframe, certaines colonnes ne sont pas nécessaire pour les tâches de classification. On peut par exemple vérifier qu'il y'a une bijection entre l'ensemble des valeurs de truthRating et l'ensemble des valeurs de ratingName."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truthRating  ratingName\n",
      "-1           OTHER         1761\n",
      " 1           FALSE         3665\n",
      " 2           MIXTURE       3247\n",
      " 3           TRUE          1327\n",
      "Name: id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "g=df.groupby(['truthRating', 'ratingName'])\n",
    "print(g['id'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut donc supprimer au choix la colonne truthRating et ratingName car les valeurs seront de toute façon transformées lors de la création des features à l'étape suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "del df['ratingName']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi supprimer la colonne language car tous les enregistrement dans le dataframe on la valeur 'English' pour cette colonne, elle n'est donc pas utile à l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "del df['language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('Dataset/claimskg_columns_removed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.b. Valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ci-dessous sont présentés les nombres de valeurs manquantes par colonnes dans le dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline : 118\n",
      "named_entities_claim : 136\n",
      "named_entities_article : 3503\n",
      "keywords : 1309\n"
     ]
    }
   ],
   "source": [
    "def count_empty_values(df):\n",
    "    columns=df.columns[df.isnull().any()].tolist()\n",
    "    for column in columns:\n",
    "        print(column + \" : \" + str(df[column].isnull().sum()))\n",
    "\n",
    "count_empty_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que les colonnes contenant des valeurs manquantes sont toutes de type 'chaîne de caractère', on ne peut donc pas effectuer de calcul de moyennes pour remplir les informations manquantes. Il n'est pas non plus envisageables de les supprimer car les autres colonnes portent des informations utiles à l'apprentissages.\n",
    "\n",
    "On s'intéresse maintenant aux enregistrements qui ne portent pas la classe cible des tâches d'apprentissage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enregistrements non FALSE, TRUE ou MIXTURE : 1761\n"
     ]
    }
   ],
   "source": [
    "print(\"Enregistrements non FALSE, TRUE ou MIXTURE : \" + str(df[df['truthRating'] == -1].count()['id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme ces enregistrements ne peuvent servir pour l'apprentissage, on peut se permettre de les supprimer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df = df[df['truthRating'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut constater l'impact sur les valeurs manquantes des quatres colonnes contenant des valeurs nulles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "named_entities_claim : 11\n",
      "named_entities_article : 2966\n",
      "keywords : 464\n"
     ]
    }
   ],
   "source": [
    "count_empty_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III.c. Pré-traitement du texte d'une affirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par importer la bibliothèque NLTK (Natural Language ToolKit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download()\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis on défini la fonction de pré-traitement du texte d'une affirmation.\n",
    "Celle-ci contient les étapes suivantes :\n",
    "- Suppression des formes contractées de la langue anglaise\n",
    "- Remplacement des chiffres par des mots\n",
    "- Suppression des ponctuations\n",
    "- Normalisation de la casse (tout est mis en minuscule)\n",
    "- Suppression des mots non utiles à la classification (Stop words)\n",
    "- Reduction des mots à leurs racines (Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import inflect\n",
    "import contractions\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "p = inflect.engine()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "def replace_contractions(text):\n",
    "    return contractions.fix(text)\n",
    "\n",
    "def tokenize(text):\n",
    "    words = []\n",
    "    \n",
    "    for sentence in sent_tokenize(text):\n",
    "        words += word_tokenize(text)\n",
    "        \n",
    "    return words\n",
    "\n",
    "def replace_numbers(word):\n",
    "    if (word.isdigit()):\n",
    "        return p.number_to_words(word)\n",
    "    else:\n",
    "        return word\n",
    "\n",
    "def remove_punctuations(words):\n",
    "    return [word for word in words if word.isalpha()]\n",
    "\n",
    "def normalize_case(word):\n",
    "    return word.lower()\n",
    "\n",
    "def filter_stop_words(words):\n",
    "    return [word for word in words if not word in stop_words]\n",
    "\n",
    "def lemmatize_word(word):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return lemmatizer.lemmatize(word, pos='v')\n",
    "\n",
    "def process_text(text):\n",
    "    text = replace_contractions(text)\n",
    "\n",
    "    words = tokenize(text)\n",
    "    words = map(replace_numbers, words)\n",
    "    words = remove_punctuations(words)\n",
    "    words = map(normalize_case, words)\n",
    "    words = filter_stop_words(words)\n",
    "    words = map(lemmatize_word, words)\n",
    "    \n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['revenue generate drill virginia coast forty million ten years revenue generate drill virginia coast forty million ten years'\n",
      " 'health insurance company pay ceos million year'\n",
      " 'ted cruz say veterans start sell cookies order raise fund' ...\n",
      " 'management charge discriminate break federal law'\n",
      " 'naacp call removal historical civil war carve stone mountain georgia'\n",
      " 'cruz try ban contraception five time']\n"
     ]
    }
   ],
   "source": [
    "df_claim_text_processed = pd.DataFrame(df['text'].apply(process_text))\n",
    "print(df_claim_text_processed['text'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# IV. Feature engeenering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV.a. Création des features extraits à partir du texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utilisé la classe TfidVectorizer pour produire à partir de chaque mots du texte pré-traité de chaque assertion une feature dont la valeur correspond à la fréquence d'apparition du mot dans le texte. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "y = df['truthRating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit réalisé en 0.071s\n",
      "Prédiction réalisée en 0.056s\n",
      "\n",
      " accuracy: 0.569868238557559 \n",
      "\n",
      "\n",
      " matrice de confusion \n",
      " [[1949  617    8]\n",
      " [ 903 1335    3]\n",
      " [ 572  378    3]]\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.76      0.65      2574\n",
      "           2       0.57      0.60      0.58      2241\n",
      "           3       0.21      0.00      0.01       953\n",
      "\n",
      "    accuracy                           0.57      5768\n",
      "   macro avg       0.45      0.45      0.41      5768\n",
      "weighted avg       0.51      0.57      0.52      5768\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from time import time\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "validation_size=0.3 #30% du jeu de données pour le test\n",
    "\n",
    "testsize= 1-validation_size\n",
    "seed=30\n",
    "\n",
    "\n",
    "\n",
    "pipeline = Pipeline([('vect', TfidfVectorizer()),\n",
    "                ('clf', SGDClassifier(loss='hinge', \n",
    "                                      penalty='l2',\n",
    "                                      alpha=1e-3, \n",
    "                                      random_state=42, \n",
    "                                      max_iter=5, tol=None)),\n",
    "               ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df_claim_text_processed['text'].values\n",
    "y = df['truthRating']\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X, \n",
    "                                               y, \n",
    "                                               train_size=validation_size, \n",
    "                                               random_state=seed,\n",
    "                                               test_size=testsize)\n",
    "\n",
    "\n",
    "t0 = time()\n",
    "pipeline.fit(X_train, y_train)\n",
    "print(\"Fit réalisé en %0.3fs\" % (time() - t0))\n",
    "\n",
    "t0 = time()\n",
    "result = pipeline.predict(X_test)\n",
    "print(\"Prédiction réalisée en %0.3fs\" % (time() - t0))\n",
    "\n",
    "print('\\n accuracy:',accuracy_score(result, y_test),'\\n')\n",
    "\n",
    "conf = confusion_matrix(y_test, result)\n",
    "print ('\\n matrice de confusion \\n',conf)\n",
    "\n",
    "print ('\\n',classification_report(y_test, result))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
